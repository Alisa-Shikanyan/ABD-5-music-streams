{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spotify_for_ml.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Категориальные фичи (фича)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16695 entries, 0 to 16694\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   artist            16695 non-null  object \n",
      " 1   track             16694 non-null  object \n",
      " 2   album             16694 non-null  object \n",
      " 3   album_type        16694 non-null  object \n",
      " 4   danceability      16694 non-null  float64\n",
      " 5   energy            16694 non-null  float64\n",
      " 6   key               16694 non-null  float64\n",
      " 7   loudness          16694 non-null  float64\n",
      " 8   speechiness       16694 non-null  float64\n",
      " 9   acousticness      16694 non-null  float64\n",
      " 10  instrumentalness  16694 non-null  float64\n",
      " 11  liveness          16694 non-null  float64\n",
      " 12  valence           16694 non-null  float64\n",
      " 13  tempo             16694 non-null  float64\n",
      " 14  stream            16694 non-null  float64\n",
      " 15  duration_min      16694 non-null  float64\n",
      " 16  is_feat           16694 non-null  float64\n",
      "dtypes: float64(13), object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя выводы, полученные на предыдущем этапе работы о типе релиза, учтем в модели признак is_album, который будет отвечать за тип релиза, в составе которого участвовал трек:\n",
    "1. **Альбом** → is_album = True (1)\n",
    "2. **Сингл** → is_album = False (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['album', 'single', nan], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.album_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_album'] = [1 if a == 'album' else 0 for a in df.album_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем признаки artist, track, album, album_type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16695, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['artist', 'track', 'album', 'album_type'], axis = 1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия\n",
    "\n",
    "Перед обучением модели сделаем следующее:\n",
    "\n",
    "1. Разделим датафрейм на датафрейм с признаками - Х и массив с целевой переменной - у (количество прослушиваний)\n",
    "\n",
    "2. После этого разобъем датафрейм на train и test в соотношении 80 / 20. Также логарифмируем целевую переменную, чтобы нормализовать ее распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "\n",
    "X = df.dropna().copy().drop(['stream'], axis = 1)\n",
    "\n",
    "#y = df['stream'].copy()\n",
    "log_y = df.dropna()['stream'].copy().apply(np.log)\n",
    "\n",
    "X_train, X_test, log_y_train, log_y_test = train_test_split(X, log_y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартизируем признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Для начала попробуем просто построить линейную регрессию \"как есть\", добавив столбец константы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Признак  Коэффициент\n",
      "0              const      17.7323\n",
      "1       danceability       0.0559\n",
      "2             energy      -0.2340\n",
      "3                key       0.0050\n",
      "4           loudness       0.2950\n",
      "5        speechiness      -0.0853\n",
      "6       acousticness      -0.1222\n",
      "7   instrumentalness      -0.0784\n",
      "8           liveness      -0.0580\n",
      "9            valence      -0.0762\n",
      "10             tempo       0.0087\n",
      "11      duration_min       0.0772\n",
      "12           is_feat       0.0945\n",
      "13          is_album       0.3361\n",
      "--------------------------------\n",
      "R² на train: 7.99%\n",
      "R² на test: 7.93%\n",
      "MSE на train: 2.4174\n",
      "MSE на test: 2.4307\n"
     ]
    }
   ],
   "source": [
    "# Добавляем константу:\n",
    "X_train_scaled_b = np.concatenate([np.ones((X_train.shape[0], 1)), X_train_scaled], axis=1)\n",
    "X_test_scaled_b = np.concatenate([np.ones((X_test.shape[0], 1)), X_test_scaled], axis=1)\n",
    "\n",
    "# Обучаем модель:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg1 = LinearRegression(fit_intercept = False).fit(X_train_scaled_b, log_y_train)\n",
    "\n",
    "log_y_train_pred = reg1.predict(X_train_scaled_b)\n",
    "log_y_test_pred = reg1.predict(X_test_scaled_b)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "r2_train = r2_score(log_y_train, log_y_train_pred)\n",
    "r2_test = r2_score(log_y_test, log_y_test_pred)\n",
    "\n",
    "mse_train = mean_squared_error(log_y_train, log_y_train_pred)\n",
    "mse_test = mean_squared_error(log_y_test, log_y_test_pred)\n",
    "\n",
    "#Вывод\n",
    "coef_table = pd.DataFrame({'Признак': ['const'] + list(X_train.columns), \n",
    "                           'Коэффициент': list(reg1.coef_.round(4))})\n",
    "\n",
    "print(coef_table)\n",
    "\n",
    "print('--------------------------------')\n",
    "print(f'R² на train: {round(r2_train * 100, 2)}%')\n",
    "print(f'R² на test: {round(r2_test * 100, 2)}%')\n",
    "print(f'MSE на train: {round(mse_train, 4)}')\n",
    "print(f'MSE на test: {round(mse_test, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R² крайне низкий, на уровне 7,9%-8%\n",
    "\n",
    "**Проверим данные на наличие мультиколлинеарности** - для этого посчитаем Variance Inflation Factor (VIF) для регрессоров в модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             feature        VIF\n",
      "0       danceability  19.108190\n",
      "1             energy  23.454353\n",
      "2                key   3.155738\n",
      "3           loudness   9.572215\n",
      "4        speechiness   2.208602\n",
      "5       acousticness   2.844166\n",
      "6   instrumentalness   1.178048\n",
      "7           liveness   2.450608\n",
      "8            valence   8.977475\n",
      "9              tempo  16.758763\n",
      "10      duration_min  18.567560\n",
      "11           is_feat   1.184559\n",
      "12          is_album   4.404166\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def vif_coeff(df):\n",
    "    vif = pd.DataFrame()\n",
    "    vif['feature'] = df.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    return vif\n",
    "\n",
    "vif = vif_coeff(X_train) \n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Коэффициенты VIF больше 10**, значит скорее всего в модели присутствует мультиколлинеарность\n",
    "https://books.econ.msu.ru/Introduction-to-Econometrics/chap04/4.1/?ysclid=mbwgropa3o744583280\n",
    "\n",
    "### 2. Попробуем убрать признаки, для которых VIF > 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['danceability', 'energy', 'tempo', 'duration_min']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = []\n",
    "for i in range(vif.shape[0]):\n",
    "    if vif.VIF[i] > 10:\n",
    "        drop_cols.append(vif.feature[i])\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Признак  Коэффициент\n",
      "0             const      17.7323\n",
      "1               key       0.0042\n",
      "2          loudness       0.1642\n",
      "3       speechiness      -0.0843\n",
      "4      acousticness      -0.0575\n",
      "5  instrumentalness      -0.1093\n",
      "6          liveness      -0.0885\n",
      "7           valence      -0.1104\n",
      "8           is_feat       0.1049\n",
      "9          is_album       0.3412\n",
      "--------------------------------\n",
      "R² на train: 7.0%\n",
      "R² на test: 6.79%\n",
      "MSE на train: 2.4436\n",
      "MSE на test: 2.4607\n"
     ]
    }
   ],
   "source": [
    "X_train2 = X_train.drop(drop_cols, axis = 1)\n",
    "X_test2 = X_test.drop(drop_cols, axis = 1)\n",
    "\n",
    "# Стандартизируем\n",
    "scaler = StandardScaler().fit(X_train2)\n",
    "X_train_scaled2 = scaler.transform(X_train2)\n",
    "X_test_scaled2 = scaler.transform(X_test2)\n",
    "\n",
    "# Добавляем константу:\n",
    "X_train_scaled_b2 = np.concatenate([np.ones((X_train2.shape[0], 1)), X_train_scaled2], axis = 1)\n",
    "X_test_scaled_b2 = np.concatenate([np.ones((X_test2.shape[0], 1)), X_test_scaled2], axis = 1)\n",
    "\n",
    "# Обучаем модель:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg2 = LinearRegression(fit_intercept = False).fit(X_train_scaled_b2, log_y_train)\n",
    "\n",
    "log_y_train_pred2 = reg2.predict(X_train_scaled_b2)\n",
    "log_y_test_pred2 = reg2.predict(X_test_scaled_b2)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "r2_train = r2_score(log_y_train, log_y_train_pred2)\n",
    "r2_test = r2_score(log_y_test, log_y_test_pred2)\n",
    "\n",
    "mse_train = mean_squared_error(log_y_train, log_y_train_pred2)\n",
    "mse_test = mean_squared_error(log_y_test, log_y_test_pred2)\n",
    "\n",
    "\n",
    "#Вывод\n",
    "coef_table = pd.DataFrame({'Признак': ['const'] + list(X_train2.columns), \n",
    "                           'Коэффициент': list(reg2.coef_.round(4))})\n",
    "\n",
    "print(coef_table)\n",
    "\n",
    "print('--------------------------------')\n",
    "print(f'R² на train: {round(r2_train * 100, 2)}%')\n",
    "print(f'R² на test: {round(r2_test * 100, 2)}%')\n",
    "print(f'MSE на train: {round(mse_train, 4)}')\n",
    "print(f'MSE на test: {round(mse_test, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R² снизился, что может говорить о том, что мы убрали важный признак, объясняющий часть дисперсии целевой переменной. \n",
    "\n",
    "### 3. Попробуем не убирать сразу все признаки с VIF > 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_linreg(X_train, X_test, log_y_train, log_y_test):\n",
    "    \n",
    "    #Стандартизируем\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    #Добавляем константу\n",
    "    X_train_scaled_b = np.concatenate([np.ones((X_train.shape[0], 1)), X_train_scaled], axis=1)\n",
    "    X_test_scaled_b = np.concatenate([np.ones((X_test.shape[0], 1)), X_test_scaled], axis=1)\n",
    "    \n",
    "    #Обучаем модель\n",
    "    from sklearn.linear_model import LinearRegression    \n",
    "    reg = LinearRegression(fit_intercept = False).fit(X_train_scaled_b, log_y_train)\n",
    "\n",
    "    log_y_train_pred = reg.predict(X_train_scaled_b)\n",
    "    log_y_test_pred = reg.predict(X_test_scaled_b)\n",
    "\n",
    "    from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "    r2_train = r2_score(log_y_train, log_y_train_pred)\n",
    "    r2_test = r2_score(log_y_test, log_y_test_pred)\n",
    "    \n",
    "    mse_train = mean_squared_error(log_y_train, log_y_train_pred)\n",
    "    mse_test = mean_squared_error(log_y_test, log_y_test_pred)\n",
    "\n",
    "    #Вывод\n",
    "    print('--------------------------------')\n",
    "    print(f'R² на train: {round(r2_train * 100, 2)}%')\n",
    "    print(f'R² на test: {round(r2_test * 100, 2)}%')\n",
    "    print(f'MSE на train: {round(mse_train, 4)}')\n",
    "    print(f'MSE на test: {round(mse_test, 4)}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Убрали признаки: ['danceability']\n",
      "--------------------------------\n",
      "R² на train: 7.91%\n",
      "R² на test: 7.93%\n",
      "MSE на train: 2.4195\n",
      "MSE на test: 2.4307\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['energy']\n",
      "--------------------------------\n",
      "R² на train: 7.34%\n",
      "R² на test: 7.06%\n",
      "MSE на train: 2.4345\n",
      "MSE на test: 2.4536\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['tempo']\n",
      "--------------------------------\n",
      "R² на train: 7.99%\n",
      "R² на test: 7.91%\n",
      "MSE на train: 2.4174\n",
      "MSE на test: 2.4311\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['duration_min']\n",
      "--------------------------------\n",
      "R² на train: 7.78%\n",
      "R² на test: 7.61%\n",
      "MSE на train: 2.4229\n",
      "MSE на test: 2.439\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['danceability', 'energy']\n",
      "--------------------------------\n",
      "R² на train: 7.14%\n",
      "R² на test: 6.99%\n",
      "MSE на train: 2.4398\n",
      "MSE на test: 2.4554\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['danceability', 'tempo']\n",
      "--------------------------------\n",
      "R² на train: 7.91%\n",
      "R² на test: 7.93%\n",
      "MSE на train: 2.4195\n",
      "MSE на test: 2.4307\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['danceability', 'duration_min']\n",
      "--------------------------------\n",
      "R² на train: 7.72%\n",
      "R² на test: 7.62%\n",
      "MSE на train: 2.4246\n",
      "MSE на test: 2.4387\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['energy', 'tempo']\n",
      "--------------------------------\n",
      "R² на train: 7.34%\n",
      "R² на test: 7.05%\n",
      "MSE на train: 2.4345\n",
      "MSE на test: 2.4538\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['energy', 'duration_min']\n",
      "--------------------------------\n",
      "R² на train: 7.17%\n",
      "R² на test: 6.81%\n",
      "MSE на train: 2.4389\n",
      "MSE на test: 2.4601\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['tempo', 'duration_min']\n",
      "--------------------------------\n",
      "R² на train: 7.78%\n",
      "R² на test: 7.6%\n",
      "MSE на train: 2.423\n",
      "MSE на test: 2.4393\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['danceability', 'energy', 'tempo']\n",
      "--------------------------------\n",
      "R² на train: 7.14%\n",
      "R² на test: 7.01%\n",
      "MSE на train: 2.4399\n",
      "MSE на test: 2.4549\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['danceability', 'energy', 'duration_min']\n",
      "--------------------------------\n",
      "R² на train: 7.0%\n",
      "R² на test: 6.77%\n",
      "MSE на train: 2.4435\n",
      "MSE на test: 2.4613\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['danceability', 'tempo', 'duration_min']\n",
      "--------------------------------\n",
      "R² на train: 7.72%\n",
      "R² на test: 7.63%\n",
      "MSE на train: 2.4246\n",
      "MSE на test: 2.4386\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Убрали признаки: ['energy', 'tempo', 'duration_min']\n",
      "--------------------------------\n",
      "R² на train: 7.17%\n",
      "R² на test: 6.81%\n",
      "MSE на train: 2.4389\n",
      "MSE на test: 2.4602\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols = ['danceability', 'energy', 'tempo', 'duration_min']\n",
    "\n",
    "combs = ['0', '1', '2', '3', \n",
    "         '01', '02', '03', \n",
    "         '12', '13', '23', \n",
    "         '012', '013', '023', '123']\n",
    "\n",
    "for comb in combs:\n",
    "    drop_cols = []\n",
    "    \n",
    "    for i in comb:\n",
    "        drop_cols.append(cols[int(i)])\n",
    "        \n",
    "    X_train_viftest = X_train.drop(drop_cols, axis = 1)\n",
    "    X_test_viftest = X_test.drop(drop_cols, axis = 1)\n",
    "    \n",
    "    print('--------------------------------')\n",
    "    print(f'Убрали признаки: {drop_cols}')\n",
    "    metrics_linreg(X_train_viftest, X_test_viftest, log_y_train, log_y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальный R² получился, когда был убран только признак ***tempo***\n",
    "\n",
    "При этом R² и MSE совпадают со значениями до удаления признаков, что говорит о том, что он не влияет на качество модели и вероятно не имеет значимого влияния на целевую переменную. \n",
    "\n",
    "В контексте данных, с которыми мы работаем, можно предположить, что *базовые* свойства композиций (длительность, темп) \"зашиты\" в *производные* характеристики треков - energy, danceability, liveness и др.\n",
    "\n",
    "Поскольку VIF у 4 переменных сильно высокий, а значительного прироста в качестве не наблюдается, оставим только базовые параметры в целях улучшения интерпретируемости и сохранения потенциально важной информации о композициях:\n",
    "\n",
    "**Оставляем:**\n",
    "* duration_min\n",
    "* tempo\n",
    "\n",
    "**Убираем:**\n",
    "* danceability\n",
    "* energy\n",
    "\n",
    "**При прочих равных характеристики модели:**\n",
    "* R² на train: 7.14%\n",
    "* R² на test: 6.99%\n",
    "* MSE на train: 2.4398\n",
    "* MSE на test: 2.4554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Попробуем использовать Регуляризацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_linereg(X_train, X_test, log_y_train, log_y_test, alpha, reg_type, drop_cols):\n",
    "    \n",
    "    from sklearn.linear_model import Ridge, Lasso\n",
    "    \n",
    "    X_train_r = X_train.drop(drop_cols, axis = 1)\n",
    "    X_test_r = X_test.drop(drop_cols, axis = 1)\n",
    "\n",
    "    # Стандартизируем\n",
    "    scaler = StandardScaler().fit(X_train_r)\n",
    "    X_train_scaled_r = scaler.transform(X_train_r)\n",
    "    X_test_scaled_r = scaler.transform(X_test_r)\n",
    "\n",
    "    # Добавляем константу:\n",
    "    X_train_scaled_b_r = np.concatenate([np.ones((X_train_r.shape[0], 1)), X_train_scaled_r], axis = 1)\n",
    "    X_test_scaled_b_r = np.concatenate([np.ones((X_test_r.shape[0], 1)), X_test_scaled_r], axis = 1)\n",
    "\n",
    "\n",
    "    # Обучаем:\n",
    "    if reg_type == 'l1':\n",
    "        model = Lasso(alpha = alpha, fit_intercept = False).fit(X_train_scaled_b_r, log_y_train)\n",
    "    else:\n",
    "        model = Ridge(alpha = alpha, fit_intercept = False).fit(X_train_scaled_b_r, log_y_train)\n",
    "    \n",
    "    log_y_train_pred = model.predict(X_train_scaled_b_r)\n",
    "    log_y_test_pred = model.predict(X_test_scaled_b_r)\n",
    "\n",
    "\n",
    "    # Выводим:\n",
    "    r2_train = r2_score(log_y_train, log_y_train_pred)\n",
    "    r2_test = r2_score(log_y_test, log_y_test_pred)\n",
    "    \n",
    "    mse_train = mean_squared_error(log_y_train, log_y_train_pred)\n",
    "    mse_test = mean_squared_error(log_y_test, log_y_test_pred)\n",
    "    print('--------------------------------')\n",
    "    print(f'Alpha = {alpha}')\n",
    "    print('--------------------------------')\n",
    "    print(f'R² на train: {round(r2_train * 100, 2)}%')\n",
    "    print(f'R² на test: {round(r2_test * 100, 2)}%')\n",
    "    print(f'MSE на train: {round(mse_train, 4)}')\n",
    "    print(f'MSE на test: {round(mse_test, 4)}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, как меняются показатели моделей при разных alpha:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 регуляризация (Lasso)\n",
      "--------------------------------\n",
      "Alpha = 0.1\n",
      "--------------------------------\n",
      "R² на train: 4.1%\n",
      "R² на test: 4.26%\n",
      "MSE на train: 2.5198\n",
      "MSE на test: 2.5274\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 0.5\n",
      "--------------------------------\n",
      "R² на train: -9.52%\n",
      "R² на test: -8.92%\n",
      "MSE на train: 2.8774\n",
      "MSE на test: 2.8755\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 1\n",
      "--------------------------------\n",
      "R² на train: -38.06%\n",
      "R² на test: -36.77%\n",
      "MSE на train: 3.6274\n",
      "MSE на test: 3.6108\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 10\n",
      "--------------------------------\n",
      "R² на train: -3806.05%\n",
      "R² на test: -3776.81%\n",
      "MSE на train: 102.6274\n",
      "MSE на test: 102.3462\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 50\n",
      "--------------------------------\n",
      "R² на train: -11967.45%\n",
      "R² на test: -11890.79%\n",
      "MSE на train: 317.0602\n",
      "MSE на test: 316.5517\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 100\n",
      "--------------------------------\n",
      "R² на train: -11967.45%\n",
      "R² на test: -11890.79%\n",
      "MSE на train: 317.0602\n",
      "MSE на test: 316.5517\n",
      "--------------------------------\n",
      "################################\n",
      "--------------------------------\n",
      "L2 регуляризация (Ridge)\n",
      "--------------------------------\n",
      "Alpha = 0.1\n",
      "--------------------------------\n",
      "R² на train: 7.14%\n",
      "R² на test: 6.99%\n",
      "MSE на train: 2.4398\n",
      "MSE на test: 2.4554\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 0.5\n",
      "--------------------------------\n",
      "R² на train: 7.14%\n",
      "R² на test: 6.99%\n",
      "MSE на train: 2.4398\n",
      "MSE на test: 2.4554\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 1\n",
      "--------------------------------\n",
      "R² на train: 7.14%\n",
      "R² на test: 6.99%\n",
      "MSE на train: 2.4398\n",
      "MSE на test: 2.4554\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 10\n",
      "--------------------------------\n",
      "R² на train: 7.13%\n",
      "R² на test: 6.99%\n",
      "MSE на train: 2.44\n",
      "MSE на test: 2.4555\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 50\n",
      "--------------------------------\n",
      "R² на train: 6.97%\n",
      "R² на test: 6.83%\n",
      "MSE на train: 2.4442\n",
      "MSE на test: 2.4596\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 100\n",
      "--------------------------------\n",
      "R² на train: 6.48%\n",
      "R² на test: 6.35%\n",
      "MSE на train: 2.4572\n",
      "MSE на test: 2.4724\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lasso (L1)\n",
    "print('L1 регуляризация (Lasso)')\n",
    "for alpha in (0.1, 0.5, 1, 10, 50, 100):\n",
    "    reg_linereg(X_train, X_test, log_y_train, log_y_test, alpha, reg_type = 'l1', drop_cols = ['danceability', 'energy'])\n",
    "\n",
    "print('################################')\n",
    "print('--------------------------------')\n",
    "# Ridge (L2)\n",
    "print('L2 регуляризация (Ridge)')\n",
    "for alpha in (0.1, 0.5, 1, 10, 50, 100):\n",
    "    reg_linereg(X_train, X_test, log_y_train, log_y_test, alpha, reg_type = 'l2', drop_cols = ['danceability', 'energy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы:**\n",
    "1. При использовании Lasso с alpha > 0.1 модель активно зануляет признаки, из-за чего R² становится отрицательным - модель работает хуже, чем предсказание по средним значениям\n",
    "2. При использовании Ridge с alpha <= 10 значительных изменений в R² нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полиномиальные фичи\n",
    "\n",
    "Попробуем добавить полиномиальные фичи в модель с регуляризацией, чтобы проработать возможную нелинейность взаимосвязей с целевой переменной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем изначальные данные:\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "\n",
    "cols = X_train.columns\n",
    "\n",
    "train_poly = poly.fit_transform(X_train)\n",
    "test_poly = poly.transform(X_test)\n",
    "\n",
    "X_train_poly = pd.DataFrame(train_poly, columns = poly.get_feature_names_out())\n",
    "X_test_poly = pd.DataFrame(test_poly, columns = poly.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 регуляризация (Lasso)\n",
      "--------------------------------\n",
      "Alpha = 0.1\n",
      "--------------------------------\n",
      "R² на train: 5.46%\n",
      "R² на test: 5.34%\n",
      "MSE на train: 2.484\n",
      "MSE на test: 2.4989\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 0.5\n",
      "--------------------------------\n",
      "R² на train: -9.52%\n",
      "R² на test: -8.92%\n",
      "MSE на train: 2.8774\n",
      "MSE на test: 2.8755\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 1\n",
      "--------------------------------\n",
      "R² на train: -38.06%\n",
      "R² на test: -36.77%\n",
      "MSE на train: 3.6274\n",
      "MSE на test: 3.6108\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 10\n",
      "--------------------------------\n",
      "R² на train: -3806.05%\n",
      "R² на test: -3776.81%\n",
      "MSE на train: 102.6274\n",
      "MSE на test: 102.3462\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 50\n",
      "--------------------------------\n",
      "R² на train: -11967.45%\n",
      "R² на test: -11890.79%\n",
      "MSE на train: 317.0602\n",
      "MSE на test: 316.5517\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 100\n",
      "--------------------------------\n",
      "R² на train: -11967.45%\n",
      "R² на test: -11890.79%\n",
      "MSE на train: 317.0602\n",
      "MSE на test: 316.5517\n",
      "--------------------------------\n",
      "################################\n",
      "--------------------------------\n",
      "L2 регуляризация (Ridge)\n",
      "--------------------------------\n",
      "Alpha = 0.1\n",
      "--------------------------------\n",
      "R² на train: 10.85%\n",
      "R² на test: 9.48%\n",
      "MSE на train: 2.3425\n",
      "MSE на test: 2.3897\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 0.5\n",
      "--------------------------------\n",
      "R² на train: 10.85%\n",
      "R² на test: 9.48%\n",
      "MSE на train: 2.3425\n",
      "MSE на test: 2.3896\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 1\n",
      "--------------------------------\n",
      "R² на train: 10.84%\n",
      "R² на test: 9.49%\n",
      "MSE на train: 2.3425\n",
      "MSE на test: 2.3895\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 10\n",
      "--------------------------------\n",
      "R² на train: 10.83%\n",
      "R² на test: 9.52%\n",
      "MSE на train: 2.343\n",
      "MSE на test: 2.3885\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 50\n",
      "--------------------------------\n",
      "R² на train: 10.55%\n",
      "R² на test: 9.37%\n",
      "MSE на train: 2.3501\n",
      "MSE на test: 2.3926\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Alpha = 100\n",
      "--------------------------------\n",
      "R² на train: 9.93%\n",
      "R² на test: 8.81%\n",
      "MSE на train: 2.3666\n",
      "MSE на test: 2.4073\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lasso (L1)\n",
    "print('L1 регуляризация (Lasso)')\n",
    "for alpha in (0.1, 0.5, 1, 10, 50, 100):\n",
    "    reg_linereg(X_train_poly, X_test_poly, log_y_train, log_y_test, alpha, reg_type = 'l1', drop_cols = [])\n",
    "\n",
    "print('################################')\n",
    "print('--------------------------------')\n",
    "# Ridge (L2)\n",
    "print('L2 регуляризация (Ridge)')\n",
    "for alpha in (0.1, 0.5, 1, 10, 50, 100):\n",
    "    reg_linereg(X_train_poly, X_test_poly, log_y_train, log_y_test, alpha, reg_type = 'l2', drop_cols = [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**С точки зрения R² лучше справилась Ridge.**\n",
    "\n",
    "Возьмем модель с alpha = 50 и посмотрим на коэффициенты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Признак  Коэффициент\n",
      "0                            const      17.6661\n",
      "1                     duration_min       0.6192\n",
      "2                  energy is_album       0.3768\n",
      "3            danceability loudness       0.2782\n",
      "4                   energy valence       0.2570\n",
      "5                         loudness       0.2464\n",
      "6                   danceability^2       0.2041\n",
      "7               tempo duration_min       0.1777\n",
      "8                speechiness tempo       0.1708\n",
      "9             duration_min is_feat       0.1686\n",
      "10       danceability acousticness       0.1597\n",
      "11                    danceability       0.1590\n",
      "12              danceability tempo       0.1549\n",
      "13                      loudness^2       0.1370\n",
      "14        speechiness duration_min       0.1339\n",
      "15                  loudness tempo       0.0993\n",
      "16                instrumentalness       0.0964\n",
      "17                    acousticness       0.0916\n",
      "18             energy duration_min       0.0838\n",
      "19            danceability is_feat       0.0811\n",
      "20       loudness instrumentalness       0.0800\n",
      "21                        liveness       0.0795\n",
      "22                       key tempo       0.0779\n",
      "23                valence is_album       0.0734\n",
      "24                liveness valence       0.0642\n",
      "25               loudness liveness       0.0632\n",
      "26             speechiness valence       0.0616\n",
      "27                 valence is_feat       0.0603\n",
      "28                         is_feat       0.0544\n",
      "29                       is_feat^2       0.0544\n",
      "30            loudness speechiness       0.0530\n",
      "31                 key speechiness       0.0469\n",
      "32                  tempo is_album       0.0418\n",
      "33                 energy loudness       0.0406\n",
      "34                      liveness^2       0.0400\n",
      "35                  liveness tempo       0.0380\n",
      "36           liveness duration_min       0.0357\n",
      "37        instrumentalness valence       0.0289\n",
      "38    speechiness instrumentalness       0.0284\n",
      "39       instrumentalness is_album       0.0274\n",
      "40                         valence       0.0273\n",
      "41                           key^2       0.0266\n",
      "42                    key liveness       0.0266\n",
      "43                loudness is_feat       0.0220\n",
      "44            speechiness liveness       0.0217\n",
      "45                key duration_min       0.0202\n",
      "46              instrumentalness^2       0.0194\n",
      "47                      is_album^2       0.0167\n",
      "48                        is_album       0.0167\n",
      "49              acousticness tempo       0.0147\n",
      "50        speechiness acousticness       0.0134\n",
      "51                     key is_feat       0.0120\n",
      "52   instrumentalness duration_min       0.0099\n",
      "53           duration_min is_album       0.0063\n",
      "54                     speechiness       0.0028\n",
      "55                   speechiness^2      -0.0006\n",
      "56                             key      -0.0054\n",
      "57                    key loudness      -0.0095\n",
      "58   acousticness instrumentalness      -0.0113\n",
      "59               liveness is_album      -0.0126\n",
      "60   danceability instrumentalness      -0.0141\n",
      "61                         tempo^2      -0.0180\n",
      "62                      energy key      -0.0261\n",
      "63            acousticness is_feat      -0.0300\n",
      "64           danceability liveness      -0.0326\n",
      "65            key instrumentalness      -0.0335\n",
      "66       instrumentalness liveness      -0.0367\n",
      "67             energy acousticness      -0.0372\n",
      "68                     key valence      -0.0381\n",
      "69          instrumentalness tempo      -0.0388\n",
      "70           acousticness liveness      -0.0408\n",
      "71                    key is_album      -0.0424\n",
      "72                danceability key      -0.0463\n",
      "73                key acousticness      -0.0468\n",
      "74                liveness is_feat      -0.0484\n",
      "75        instrumentalness is_feat      -0.0504\n",
      "76                  energy is_feat      -0.0555\n",
      "77             speechiness is_feat      -0.0608\n",
      "78            valence duration_min      -0.0709\n",
      "79                is_feat is_album      -0.0711\n",
      "80           loudness acousticness      -0.0717\n",
      "81       danceability duration_min      -0.0775\n",
      "82           acousticness is_album      -0.0781\n",
      "83                  acousticness^2      -0.0791\n",
      "84                   tempo is_feat      -0.0845\n",
      "85           loudness duration_min      -0.0847\n",
      "86                          energy      -0.0865\n",
      "87         energy instrumentalness      -0.0939\n",
      "88            speechiness is_album      -0.1013\n",
      "89                   valence tempo      -0.1027\n",
      "90                loudness valence      -0.1064\n",
      "91       acousticness duration_min      -0.1080\n",
      "92            acousticness valence      -0.1092\n",
      "93                    energy tempo      -0.1261\n",
      "94             danceability energy      -0.1267\n",
      "95                       valence^2      -0.1281\n",
      "96           danceability is_album      -0.1291\n",
      "97                           tempo      -0.1331\n",
      "98                        energy^2      -0.1423\n",
      "99        danceability speechiness      -0.1624\n",
      "100              loudness is_album      -0.1846\n",
      "101           danceability valence      -0.1893\n",
      "102             energy speechiness      -0.2018\n",
      "103                energy liveness      -0.2099\n",
      "104                 duration_min^2      -0.7059\n",
      "-----------------------------------------------\n",
      "Alpha = 50\n",
      "-----------------------------------------------\n",
      "R² на train: 10.55%\n",
      "R² на test: 9.37%\n",
      "MSE на train: 2.3501\n",
      "MSE на test: 2.3926\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Стандартизируем\n",
    "scaler = StandardScaler().fit(X_train_poly)\n",
    "X_train_scaled_r = scaler.transform(X_train_poly)\n",
    "X_test_scaled_r = scaler.transform(X_test_poly)\n",
    "\n",
    "# Добавляем константу:\n",
    "X_train_scaled_b_r = np.concatenate([np.ones((X_train.shape[0], 1)), X_train_scaled_r], axis = 1)\n",
    "X_test_scaled_b_r = np.concatenate([np.ones((X_test.shape[0], 1)), X_test_scaled_r], axis = 1)\n",
    "\n",
    "\n",
    "# Обучаем:\n",
    "alpha = 50\n",
    "model = Ridge(alpha = alpha, fit_intercept = False).fit(X_train_scaled_b_r, log_y_train)\n",
    "    \n",
    "log_y_train_pred = model.predict(X_train_scaled_b_r)\n",
    "log_y_test_pred = model.predict(X_test_scaled_b_r)\n",
    "\n",
    "\n",
    "# Выводим:\n",
    "r2_train = r2_score(log_y_train, log_y_train_pred)\n",
    "r2_test = r2_score(log_y_test, log_y_test_pred)\n",
    "    \n",
    "mse_train = mean_squared_error(log_y_train, log_y_train_pred)\n",
    "mse_test = mean_squared_error(log_y_test, log_y_test_pred)\n",
    "\n",
    "coef_table = pd.DataFrame({'Признак': ['const'] + list(X_train_poly.columns), \n",
    "                           'Коэффициент': list(model.coef_.round(4))})\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(coef_table.sort_values(by = 'Коэффициент', ascending = False).reset_index(drop = True))\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "\n",
    "print('-----------------------------------------------')\n",
    "print(f'Alpha = {alpha}')\n",
    "print('-----------------------------------------------')\n",
    "print(f'R² на train: {round(r2_train * 100, 2)}%')\n",
    "print(f'R² на test: {round(r2_test * 100, 2)}%')\n",
    "print(f'MSE на train: {round(mse_train, 4)}')\n",
    "print(f'MSE на test: {round(mse_test, 4)}')\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "1. **Наибольшее влияние имеют переменные duration_min (положительное) и duration_min^2 (отрицательное)**\n",
    "\n",
    "С точки зрения интерпретации можно предположить, что при значительном увеличении продолжительности трека его популярность снижается\n",
    "\n",
    "2. **Коэффициенты при loudness и loudness^2 положительны**\n",
    "\n",
    "т.е. в среднем при более высокой громкости трека у него больше прослушиваний. Это может подтверждать предположение об использовании громкости в качестве прокси качества трека (т.к. для достижения более высокой громкости нужно более качественное сведение композиции)\n",
    "\n",
    "3. **R² на test = 9.37%**, \n",
    "\n",
    "что очень мало и говорит о плохой объясняющей силе модели, поэтому ***выводы не являются надёжными.***\n",
    "\n",
    "Возможно стоит попробовать более сложные типы моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бустинг\n",
    "\n",
    "Попробуем использовать другие модели, например **LightGBM (*Light Gradient Boosting Machine*)** - ансамблевая модель, основанная на стохастическом градиентном бустинге\n",
    "\n",
    "**Для начала используем изначальные данные:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "R² на train: 15.35%\n",
      "R² на test: 9.87%\n",
      "RMSE на train: 1.4913\n",
      "RMSE на test: 1.5425\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm = LGBMRegressor(n_estimators = 100, \n",
    "                     learning_rate = 0.1, \n",
    "                     max_depth = 3, \n",
    "                     random_state = 42)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lgbm.fit(X_train_scaled, log_y_train)\n",
    "\n",
    "log_y_train_pred_lgbm = lgbm.predict(X_train_scaled)\n",
    "log_y_test_pred_lgbm = lgbm.predict(X_test_scaled)\n",
    "\n",
    "r2_train = r2_score(log_y_train, log_y_train_pred_lgbm)\n",
    "r2_test = r2_score(log_y_test, log_y_test_pred_lgbm)\n",
    "\n",
    "rmse_train = mean_squared_error(log_y_train, log_y_train_pred_lgbm) ** 0.5\n",
    "rmse_test = mean_squared_error(log_y_test, log_y_test_pred_lgbm) ** 0.5\n",
    "\n",
    "print('--------------------------------')\n",
    "print(f'R² на train: {round(r2_train * 100, 2)}%')\n",
    "print(f'R² на test: {round(r2_test * 100, 2)}%')\n",
    "print(f'RMSE на train: {round(rmse_train, 4)}')\n",
    "print(f'RMSE на test: {round(rmse_test, 4)}')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Даже на изначальных данных модель показывает значительный прирост R², однако на train он сильно выше, чем на test, что может говорить о наличии переобучения.\n",
    "\n",
    "**Добавим полиномиальные признаки, чтобы улучшить модель:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "R² на train: 17.3%\n",
      "R² на test: 10.49%\n",
      "RMSE на train: 1.4741\n",
      "RMSE на test: 1.5372\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(n_estimators = 100, \n",
    "                     learning_rate = 0.1, \n",
    "                     max_depth = 3, \n",
    "                     random_state = 42)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_poly)\n",
    "X_train_scaled = scaler.transform(X_train_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "lgbm.fit(X_train_scaled, log_y_train)\n",
    "\n",
    "log_y_train_pred_lgbm = lgbm.predict(X_train_scaled)\n",
    "log_y_test_pred_lgbm = lgbm.predict(X_test_scaled)\n",
    "\n",
    "r2_train = r2_score(log_y_train, log_y_train_pred_lgbm)\n",
    "r2_test = r2_score(log_y_test, log_y_test_pred_lgbm)\n",
    "\n",
    "rmse_train = mean_squared_error(log_y_train, log_y_train_pred_lgbm) ** 0.5\n",
    "rmse_test = mean_squared_error(log_y_test, log_y_test_pred_lgbm) ** 0.5\n",
    "\n",
    "print('--------------------------------')\n",
    "print(f'R² на train: {round(r2_train * 100, 2)}%')\n",
    "print(f'R² на test: {round(r2_test * 100, 2)}%')\n",
    "print(f'RMSE на train: {round(rmse_train, 4)}')\n",
    "print(f'RMSE на test: {round(rmse_test, 4)}')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подберём оптимальные параметры LGBM с помощью Optuna:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры Optuna: {'n_estimators': 87, 'max_depth': 13}\n",
      "--------------------------------\n",
      "R² на train: 37.7%\n",
      "R² на test: 12.91%\n",
      "RMSE на train: 1.2794\n",
      "RMSE на test: 1.5163\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_poly)\n",
    "X_train_scaled = scaler.transform(X_train_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    \n",
    "    lgbm = LGBMRegressor(n_estimators = n_estimators, \n",
    "                         max_depth = max_depth, \n",
    "                         random_state = 42)\n",
    "    \n",
    "    score = cross_val_score(lgbm, X_train_scaled, log_y_train, cv = 3, \n",
    "                            scoring = 'neg_mean_squared_error', \n",
    "                            n_jobs=-1)\n",
    "    return -score.mean()\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(sampler = TPESampler(seed = 42), direction = 'minimize')\n",
    "study.optimize(objective, n_trials = 20)\n",
    "\n",
    "print(f'Лучшие параметры Optuna: {study.best_params}')\n",
    "\n",
    "best_lgbm = LGBMRegressor(**study.best_params, random_state = 42)\n",
    "best_lgbm.fit(X_train_scaled, log_y_train)\n",
    "\n",
    "log_y_train_pred_lgbm = best_lgbm.predict(X_train_scaled)\n",
    "log_y_test_pred_lgbm = best_lgbm.predict(X_test_scaled)\n",
    "\n",
    "r2_train = r2_score(log_y_train, log_y_train_pred_lgbm)\n",
    "r2_test = r2_score(log_y_test, log_y_test_pred_lgbm)\n",
    "\n",
    "rmse_train = mean_squared_error(log_y_train, log_y_train_pred_lgbm) ** 0.5\n",
    "rmse_test = mean_squared_error(log_y_test, log_y_test_pred_lgbm) ** 0.5\n",
    "\n",
    "print('--------------------------------')\n",
    "print(f'R² на train: {round(r2_train * 100, 2)}%')\n",
    "print(f'R² на test: {round(r2_test * 100, 2)}%')\n",
    "print(f'RMSE на train: {round(rmse_train, 4)}')\n",
    "print(f'RMSE на test: {round(rmse_test, 4)}')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R² сильно больше на train, чем на test.** Вероятно, в модели наблюдается переобучение.\n",
    "\n",
    "Попробуем использовать стекинговую модель не только с LGBM, но и с XGBoost и CatBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "R² на train: 49.03%\n",
      "R² на test: 13.9%\n",
      "RMSE на train: 1.1572\n",
      "RMSE на test: 1.5077\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "#from sklearn.ensemble import BaggingRegressor\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_poly)\n",
    "X_train_scaled = scaler.transform(X_train_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "stack = StackingRegressor(estimators = [('xgb', xgb.XGBRegressor(n_estimators = 100, \n",
    "                                                                 random_state = 42)), \n",
    "                                        ('cat', CatBoostRegressor(n_estimators = 100, \n",
    "                                                                  verbose = 0, \n",
    "                                                                  random_state = 42)),\n",
    "                                        ('lgbm', LGBMRegressor(n_estimators = 87, max_depth = 13, \n",
    "                                                               random_state = 42))], \n",
    "                          final_estimator = Ridge())\n",
    "\n",
    "\n",
    "\n",
    "stack.fit(X_train_scaled, log_y_train)\n",
    "\n",
    "log_y_train_pred_stack = stack.predict(X_train_scaled)\n",
    "log_y_test_pred_stack = stack.predict(X_test_scaled)\n",
    "\n",
    "r2_train = r2_score(log_y_train, log_y_train_pred_stack)\n",
    "r2_test = r2_score(log_y_test, log_y_test_pred_stack)\n",
    "\n",
    "rmse_train = mean_squared_error(log_y_train, log_y_train_pred_stack) ** 0.5\n",
    "rmse_test = mean_squared_error(log_y_test, log_y_test_pred_stack) ** 0.5\n",
    "\n",
    "\n",
    "print('--------------------------------')\n",
    "print(f'R² на train: {round(r2_train * 100, 2)}%')\n",
    "print(f'R² на test: {round(r2_test * 100, 2)}%')\n",
    "print(f'RMSE на train: {round(rmse_train, 4)}')\n",
    "print(f'RMSE на test: {round(rmse_test, 4)}')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. R² значительно вырос на train, при этом на test увеличился на 1%. \n",
    "2. Наблюдается переобучение\n",
    "3. Бустинговые модели лучше работают в данном случае, чем обычная линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "В рамках данного этапа мы построили модель для предсказания значений целевой переменной **stream** (логарифм количества прослушиваний музыкальной композиции):\n",
    "\n",
    "1. При построении обычной линейной регрессии коэффициент детерминации R² у моделей находится в диапазоне 6%-8%, что говорит о плохой объясняющей силе модели. Также, признаки коррелированы между собой, из-за чего в модели присутствует мультиколлинеарность. \n",
    "\n",
    "При удалении регрессоров с высоким VIF ***R² на train составил 7.14%, R² на test составил 6.99%***\n",
    "\n",
    "2. При использовании регуляризации лучше работает Ridge, поскольку Lasso активно зануляет признаки и R² становится отрицательным. При этом относительно обычной регрессии результаты меняются не сильно. Предположительно, основной причиной низкого R² и отсутствия изменений при регуляризации является недостаток важных признаков в данных.\n",
    "\n",
    "\n",
    "3. Для улучшения модели и её объясняющей силы в модель были добавлены полиномиальные признаки степени 2 для всех регрессоров. При использоваии Ridge R² удалось повысить ***на train до 10.55%, и на test до 9.37%***\n",
    "\n",
    "\n",
    "4. С использованием бустинговых моделей объясняющая сила значительно улучшилась, однако при этом R² на train сильно выше, чем на test, что говорит о наличии переобучения. **Наилучший результат показала стекинговая модель с использованием LGBM, XGBoost и CatBoost**, ***R² на train составил 49.03%, на test 13.9%***, однако модель явно переобучилась.\n",
    "\n",
    "\n",
    "5. В рамках текущей работы не удалось построить модель, которая бы качественно предсказывала количество прослушиваний по имеющимся переменным, и при дальнейших исследованиях будет крайне необходимо дополнить анализ и другими характеристиками, *например жанрами, годом выхода композиции и т.д.* Таким образом качество моделей должно значительно возрасти, поскольку в текущей реализации в данных явно не хватает важных регрессоров, из-за чего модель переобучается и не удается повысить объясняющую силу."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
